# -*- coding: utf-8 -*-
"""Análise segmentação e estimativa de pose.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fVtht6KmU6XknIjtpQohMjqwhVQfaA87
"""

#Instala o pacote da ultralytics
!pip install ultralytics

#Importações de bibliotecas
import pandas as pd
import os

#Define variaveis para cada imagem
#Variáveis referentes as 100 imagens do vídeo 7 do conjunto de teste
#As imagens que possuem alguma interação sendo da criança -> plusme ou terapeuta -> plusme, as variáveis recebem 1, as imagens que não possuem nenhuma interação, as variáveis recebem 0
asd7_46 = 1
asd7_50 = 1
asd7_60 = 1
asd7_65 = 1
asd7_97 = 0
asd7_103 = 0
asd7_108 = 0
asd7_138 = 1
asd7_139 = 1
asd7_149 = 0

asd7_176 = 0
asd7_204 = 0
asd7_217 = 0
asd7_218 = 0
asd7_238 = 1
asd7_256 = 0
asd7_264 = 0
asd7_277 = 0
asd7_278 = 0
asd7_286 = 0

asd7_296 = 0
asd7_297 = 0
asd7_309 = 0
asd7_315 = 0
asd7_322 = 0
asd7_343 = 1
asd7_348 = 1
asd7_349 = 1
asd7_353 = 1
asd7_364 = 1

asd7_365 = 1
asd7_380 = 0
asd7_395 = 0
asd7_406 = 0
asd7_427 = 0
asd7_458 = 1
asd7_477 = 0
asd7_488 = 0
asd7_503 = 1
asd7_504 = 1

asd7_505 = 1
asd7_508 = 1
asd7_524 = 1
asd7_567 = 1
asd7_593 = 1
asd7_615 = 1
asd7_621 = 1
asd7_633 = 1
asd7_638 = 1
asd7_647 = 0

asd7_655 = 1
asd7_679 = 1
asd7_701 = 1
asd7_707 = 1
asd7_719 = 1
asd7_753 = 1
asd7_773 = 1
asd7_777 = 1
asd7_793 = 0
asd7_796 = 0

asd7_821 = 1
asd7_835 = 1
asd7_842 = 0
asd7_848 = 0
asd7_881 = 0
asd7_888 = 0
asd7_897 = 0
asd7_929 = 1
asd7_930 = 1
asd7_937 = 1

asd7_938 = 1
asd7_954 = 0
asd7_967 = 0
asd7_1044 = 0
asd7_1082 = 0
asd7_1089 = 1
asd7_1094 = 1
asd7_1095 = 1
asd7_1099 = 1
asd7_1116 = 1

asd7_1121 = 1
asd7_1126 = 1
asd7_1141 = 0
asd7_1143 = 0
asd7_1149 = 0
asd7_1151 = 0
asd7_1179 = 0
asd7_1184 = 0
asd7_1194 = 1
asd7_1201 = 1

asd7_1205 = 1
asd7_1219 = 1
asd7_1231 = 0
asd7_1232 = 0
asd7_1234 = 0
asd7_1247 = 0
asd7_1248 = 0
asd7_1250 = 0
asd7_1256 = 0
asd7_1275 = 1

#Variáveis referentes as 100 imagens do vídeo 8 do conjunto de teste
asd8_2 = 0
asd8_13 = 1
asd8_14 = 1
asd8_28 = 0
asd8_32 = 0
asd8_45 = 0
asd8_48 = 0
asd8_54 = 0
asd8_86 = 1
asd8_103 = 0

asd8_108 = 0
asd8_118 = 0
asd8_121 = 0
asd8_122 = 0
asd8_132 = 0
asd8_136 = 0
asd8_145 = 0
asd8_146 = 1
asd8_148 = 1
asd8_152 = 1

asd8_154 = 1
asd8_158 = 1
asd8_191 = 0
asd8_198 = 1
asd8_214 = 1
asd8_215 = 1
asd8_230 = 1
asd8_236 = 1
asd8_248 = 1
asd8_252 = 1

asd8_256 = 0
asd8_271 = 1
asd8_278 = 1
asd8_286 = 1
asd8_287 = 1
asd8_296 = 1
asd8_298 = 1
asd8_300 = 1
asd8_301 = 1
asd8_303 = 1

asd8_307 = 1
asd8_308 = 1
asd8_318 = 1
asd8_349 = 0
asd8_350 = 0
asd8_352 = 0
asd8_367 = 0
asd8_371 = 0
asd8_372 = 0
asd8_381 = 1

asd8_382 = 1
asd8_383 = 1
asd8_407 = 1
asd8_413 = 1
asd8_415 = 1
asd8_417 = 1
asd8_424 = 1
asd8_426 = 1
asd8_438 = 1
asd8_445 = 1

asd8_446 = 1
asd8_452 = 1
asd8_463 = 1
asd8_471 = 1
asd8_481 = 1
asd8_505 = 1
asd8_511 = 1
asd8_542 = 1
asd8_548 = 1
asd8_550 = 1

asd8_557 = 1
asd8_559 = 1
asd8_562 = 1
asd8_575 = 1
asd8_593 = 1
asd8_602 = 1
asd8_610 = 1
asd8_613 = 1
asd8_623 = 1
asd8_625 = 1

asd8_626 = 1
asd8_630 = 1
asd8_636 = 1
asd8_640 = 1
asd8_645 = 1
asd8_650 = 1
asd8_654 = 1
asd8_658 = 1
asd8_663 = 1
asd8_666 = 1

asd8_668 = 1
asd8_669 = 1
asd8_674 = 1
asd8_684 = 1
asd8_686 = 1
asd8_696 = 1
asd8_703 = 0
asd8_705 = 0
asd8_709 = 1
asd8_712 = 0

#Cria array com as variáveis referentes a cada imagem com os valores reais se possui ou não interação
#As variáveis foram colocadas nessa ordem porque como as variáveis são strings, essa é a ordem de classificação (ordenação alfabética)
#Obs: No computador a ordem das imagens acompanham os valores crescentes dos números, exemplo: 46, 103, 458

valores_verdadeiros_de_interacao = [asd7_103, asd7_1044, asd7_108, asd7_1082, asd7_1089, asd7_1094, asd7_1095, asd7_1099, asd7_1116, asd7_1121, asd7_1126, asd7_1141, asd7_1143, asd7_1149, asd7_1151, asd7_1179, asd7_1184, asd7_1194, asd7_1201,
asd7_1205, asd7_1219, asd7_1231, asd7_1232, asd7_1234, asd7_1247, asd7_1248, asd7_1250, asd7_1256, asd7_1275, asd7_138, asd7_139, asd7_149, asd7_176, asd7_204, asd7_217, asd7_218, asd7_238, asd7_256, asd7_264, asd7_277, asd7_278, asd7_286,
asd7_296, asd7_297, asd7_309, asd7_315, asd7_322, asd7_343, asd7_348, asd7_349, asd7_353, asd7_364, asd7_365, asd7_380, asd7_395, asd7_406, asd7_427, asd7_458, asd7_46, asd7_477, asd7_488, asd7_50, asd7_503, asd7_504, asd7_505, asd7_508,
asd7_524, asd7_567, asd7_593, asd7_60, asd7_615, asd7_621, asd7_633, asd7_638, asd7_647, asd7_65, asd7_655, asd7_679, asd7_701, asd7_707, asd7_719, asd7_753, asd7_773, asd7_777, asd7_793, asd7_796, asd7_821, asd7_835, asd7_842, asd7_848, asd7_881,
asd7_888, asd7_897, asd7_929, asd7_930, asd7_937, asd7_938, asd7_954, asd7_967, asd7_97, asd8_103, asd8_108, asd8_118, asd8_121, asd8_122, asd8_13, asd8_132, asd8_136, asd8_14, asd8_145, asd8_146, asd8_148, asd8_152, asd8_154, asd8_158, asd8_191,
asd8_198, asd8_2, asd8_214, asd8_215, asd8_230, asd8_236, asd8_248, asd8_252, asd8_256, asd8_271, asd8_278, asd8_28, asd8_286, asd8_287, asd8_296, asd8_298, asd8_300, asd8_301, asd8_303, asd8_307, asd8_308, asd8_318, asd8_32, asd8_349, asd8_350,
asd8_352, asd8_367, asd8_371, asd8_372, asd8_381, asd8_382, asd8_383, asd8_407, asd8_413, asd8_415, asd8_417, asd8_424, asd8_426, asd8_438, asd8_445, asd8_446, asd8_45, asd8_452, asd8_463, asd8_471, asd8_48, asd8_481, asd8_505, asd8_511, asd8_54,
asd8_542, asd8_548, asd8_550, asd8_557, asd8_559, asd8_562, asd8_575, asd8_593, asd8_602, asd8_610, asd8_613, asd8_623, asd8_625, asd8_626, asd8_630, asd8_636, asd8_640, asd8_645, asd8_650, asd8_654, asd8_658, asd8_663, asd8_666, asd8_668,
asd8_669, asd8_674, asd8_684, asd8_686, asd8_696, asd8_703, asd8_705, asd8_709, asd8_712, asd8_86]

print(valores_verdadeiros_de_interacao)

#Conecta o drive ao colab para usar as imagens que estão armazenadas no Drive
from google.colab import drive
drive.mount('/content/gdrive')

"""#**Verificação da heurística**

### Código para fazer a leitura de um arquivo com os dados obtidos da segmentação
"""

# Leitura do arquivo diretamente com pandas
df = pd.read_csv('/content/gdrive/MyDrive/MESTRADO/Disciplinas/Visão Computacional/Segmentação com SAM2/predict/labels/asd7-103.txt', delimiter=' ', header=None)

largura = 1920 #largura das imagens
altura = 1080 #altura das imagens

# Remover a coluna de classe (primeira coluna) e a coluna de confiança (última coluna)
coordenadas = df.iloc[:, 1:-1].values  # Selecionar apenas as colunas de coordenadas

# Criar uma lista de dicionários para organizar os dados
todas_coordenadas = []
for row in coordenadas:
  #i vai percorrer a sequência criada pelo range do tamanho da quantidade de coordenadas que possui. Iniciando do 0 e iteraando de 2 em 2
    for i in range(0, len(row), 2):  # Iterar de 2 em 2 para pares (x, y)
        #armazena na coluna x o primeiro dado desnormalizado correspondente a coordenada x
        #armazena na coluna y o primeiro dado desnormalizado correspondente a coordenada y
        #Para desnormalizar, foi multiplicado os valores x pela largura da imagem e os valores y pela altura da imagem
        todas_coordenadas.append({'x': row[i] * largura, 'y': row[i + 1] * altura})

# Criar o dataframe final
dataframe_dados_segmentacao = pd.DataFrame(todas_coordenadas)

# Exibir o resultado
print(dataframe_dados_segmentacao)

"""### Código para fazer a leitura de todos os arquivos de segmentação"""

import os
import pandas as pd

# Caminho da pasta contendo as labels de segmentação
imagens_segmentacao_labels = '/content/gdrive/MyDrive/MESTRADO/Disciplinas/Visão Computacional/Segmentação com SAM2/predict/labels'

# Ordena os arquivos na pasta em ordem alfabética
caminhos_segmentacao = sorted([os.path.join(imagens_segmentacao_labels, label) for label in os.listdir(imagens_segmentacao_labels)])

# Definições de largura e altura das imagens
largura = 1920
altura = 1080

# Processar cada arquivo na pasta
for caminho_label in caminhos_segmentacao:
    # Ler o arquivo como DataFrame
    df = pd.read_csv(caminho_label, delimiter=' ', header=None)

    # Remover a coluna de classe (primeira) e a coluna de confiabilidade (última)
    coordenadas = df.iloc[:, 1:-1].values  # Pega somente as colunas de coordenadas

    # Criar uma lista para armazenar as coordenadas de cada arquivo
    coordenadas_arquivo = []

    # Processar cada linha do arquivo
    for row in coordenadas:
        # Iterar sobre os pares (x, y) e desnormalizar
        for i in range(0, len(row), 2):
            coordenadas_arquivo.append({
                "x": row[i] * largura,  # Coordenada x desnormalizada
                "y": row[i + 1] * altura  # Coordenada y desnormalizada
            })

    # Criar um DataFrame para o arquivo atual
    dataframe_dados_segmentacao = pd.DataFrame(coordenadas_arquivo)

    # Exibir o DataFrame específico para esse arquivo
    print(f"DataFrame para o arquivo: {os.path.basename(caminho_label)}")
    print(dataframe_dados_segmentacao)
    print("\n" + "-"*50 + "\n")

"""### Verifica se algum ponto do pulso das pessoas está dentro da caixa de segmentação"""

import numpy as np
#Caminho das labels de pose
imagens_pose_labels = '/content/gdrive/MyDrive/MESTRADO/Disciplinas/Visão Computacional/Estimativa de pose com yolo 11/Testes com yolo11/runs/pose/extra_large/labels'
#Caminhos das labels de segmentação
imagens_segmentacao_labels = '/content/gdrive/MyDrive/MESTRADO/Disciplinas/Visão Computacional/Segmentação com SAM2/predict/labels'
#Ordena os arquivos de pose em ordem alfabética
caminhos_pose = sorted([os.path.join(imagens_pose_labels, label) for label in os.listdir(imagens_pose_labels)])
#Ordena os arquivos de segmentação em ordem alfabética
caminhos_segmentacao = sorted([os.path.join(imagens_segmentacao_labels, label) for label in os.listdir(imagens_segmentacao_labels)])

#cria arrays vazios para armazenar posteriormente os valores referentes a pessoa 1 e pessoa 2
pessoa1 = []
pessoa2 = []

#Define as colunas da tabela de pose
colunas_pose = ["classe", "x_caixa", "y_caixa", "w_caixa", "h_caixa", "x_nariz", "y_nariz", "nariz-visibility", "x_olho_esq", "y_olho_esq", "olho_esq-visibility",
           "x_olho_dir", "y_olho_dir", "olho_dir-visibility", "x_orelha_esq", "y_orelha_esq", "orelha_esq-visibility",
           "x_orelha_dir", "y_orelha_dir", "orelha_dir-visibility", "x_ombro_esq", "y_ombro_esq", "ombro_esq-visibility",
           "x_ombro_dir", "y_ombro_dir", "ombro_dir-visibility", "x_cotovelo_esq", "y_cotovelo_esq", "cotovelo_esq-visibility",
           "x_cotevelo_dir", "y_cotevelo_dir", "cotevelo_dir-visibility", "x_pulso_esq", "y_pulso_esq", "pulso_esq-visibility",
           "x_pulso_dir", "y_pulso_dir", "pulso_dir-visibility", "x_quadril_esq", "y_quadril_esq", "quadril_esq-visibility",
           "x_quadril_dir", "y_quadril_dir", "quadril_dir-visibility", "x_joelho_esq", "y_joelho_esq", "joelho_esq-visibility",
           "x_joelho_dir", "y_joelho_dir", "joelho_dir-visibility", "x_tornozelo_esq", "y_tornozelo_esq", "tornozelo_esq-visibility",
           "x_tornozelo_dir", "y_tornozelo_dir", "tornozelo_dir-visibility","conf"]

#Array para armazenar as predições realizadas
valor_predito_interacao_caixa_do_segmento_pose = []

largura = 1920  # Defina a largura da imagem
altura = 1080  # Defina a altura da imagem

#Itera sobre todos os arquivos
for caminho_label in caminhos_pose:
    nome_arquivo = os.path.basename(caminho_label)

    #Lê o arquivo com as coordenadas de pose
    df_pose = pd.read_csv(caminho_label, delimiter=' ', header=None, names=colunas_pose)

    caminho_label_segmento = os.path.join(imagens_segmentacao_labels, nome_arquivo)
    #Lê os arquivos com as coordenadas do segmento
    df_segmento = pd.read_csv(caminho_label_segmento, delimiter=' ', header=None)


    print(f"\nDados da imagem {caminho_label}:")

    #Itera por cada linha do arquivo de pose
    for j in range(len(df_pose)):
      #Armazena em dados o conteúdo referente a cada linha
      dados = df_pose.iloc[j]
      # Desnormalizando os valores de xywhn -> xywh
      #print(dados.iloc[32], dados.iloc[33], dados.iloc[35], dados.iloc[36])

      #x pulso esquerdo = 32
      #y pulso esquerdo = 33
      #x pulso direito = 35
      #y pulso direito = 36

      x_pulso_esquerdo = dados.iloc[32] * largura
      y_pulso_esquerdo = dados.iloc[33] * altura
      x_pulso_direito = dados.iloc[35] * largura
      y_pulso_direito = dados.iloc[36] * altura

      # Adiciona os dados da pessoa 1 à lista pessoa1
      if j == 0:
        pessoa1.extend([x_pulso_esquerdo, y_pulso_esquerdo, x_pulso_direito, y_pulso_direito])
      # Adiciona os dados da pessoa 2 à lista pessoa2
      elif j == 1:
        pessoa2.extend([x_pulso_esquerdo, y_pulso_esquerdo, x_pulso_direito, y_pulso_direito])

      print(f"Pessoa 1: {pessoa1}")
      print(f"Pessoa 2: {pessoa2}")


    #INÍCIO DO PROCESSAMENTO DOS DADOS DO SEGMENTO
    # Remover a coluna de classe (primeira) e a coluna de confiabilidade (última)
    coordenadas = df_segmento.iloc[:, 1:-1].values  # Pega somente as colunas de coordenadas

    # Criar uma lista para armazenar as coordenadas de cada arquivo
    coordenadas_arquivo = []

    # Processar cada linha do arquivo
    for row in coordenadas:
        # Iterar sobre os pares (x, y) e desnormalizar
        for i in range(0, len(row), 2):
            coordenadas_arquivo.append({
                "x": row[i] * largura,  # Coordenada x desnormalizada
                "y": row[i + 1] * altura  # Coordenada y desnormalizada
            })

    # Criar um DataFrame para o arquivo atual
    dataframe_dados_segmentacao = pd.DataFrame(coordenadas_arquivo)

    # Calcula o retângulo delimitador da segmentação a partir do menor e maior valor de x e y
    x_inicio = min(dataframe_dados_segmentacao['x'])
    x_fim = max(dataframe_dados_segmentacao['x'])
    y_inicio = min(dataframe_dados_segmentacao['y'])
    y_fim = max(dataframe_dados_segmentacao['y'])

    # Função para verificar se um ponto está dentro do retângulo
    def ponto_dentro_retangulo(x, y, min_x, max_x, min_y, max_y):
        return min_x <= x <= max_x and min_y <= y <= max_y

    # Verifica para a pessoa 1
    interacao_detectada = False
    #pessoa1[0] ou pessoa2 [0] = x_pulso_esquerdo
    #pessoa1[1] ou pessoa2 [1] = y_pulso_esquerdo
    #pessoa1[2] ou pessoa2 [2] = x_pulso_direito
    #pessoa1[3] ou pessoa2 [3] = y_pulso_direito
    if pessoa1:
      #Verifica se existe um pulso da pessoa 1 dentro da caixa delimitadora
      if ponto_dentro_retangulo(pessoa1[0], pessoa1[1], x_inicio, x_fim, y_inicio, y_fim):
          print("Pulso esquerdo da pessoa 1 está dentro da segmentação.")
          interacao_detectada = True
      if ponto_dentro_retangulo(pessoa1[2], pessoa1[3], x_inicio, x_fim, y_inicio, y_fim):
            print("Pulso direito da pessoa 1 está dentro da segmentação.")
            interacao_detectada = True

    #Verifica se existe a detecção da pessoa 2
    if pessoa2:
      #Verifica se existe um pulso da pessoa 2 dentro da caixa delimitadora
      if ponto_dentro_retangulo(pessoa2[0], pessoa2[1], x_inicio, x_fim, y_inicio, y_fim):
          print("Pulso esquerdo da pessoa 2 está dentro da caixa da segmentação.")
          interacao_detectada = True
      if ponto_dentro_retangulo(pessoa2[2], pessoa2[3], x_inicio, x_fim, y_inicio, y_fim):
            print("Pulso direito da pessoa 2 está dentro da caixa da segmentação.")
            interacao_detectada = True

  #Se a interação de um dos pulsos for detectada, adiciona o valor 1 no array predito, caso contrário adicione 0 ao array
    if interacao_detectada:
        valor_predito_interacao_caixa_do_segmento_pose.append(1)
    else:
        valor_predito_interacao_caixa_do_segmento_pose.append(0)

    pessoa1 = []
    pessoa2 = []
print(valor_predito_interacao_caixa_do_segmento_pose)

print(valor_predito_interacao_caixa_do_segmento_pose)

import pandas as pd
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, classification_report
import matplotlib.pyplot as plt

def criar_matriz_confusao(y_true, y_pred):
    """
    Cria uma matriz de confusão e a plota.

    Args:
        y_true: O vetor de rótulos verdadeiros.
        y_pred: O vetor de rótulos previstos.
        classes: Uma lista com os nomes das classes.
    """

    cm = confusion_matrix(y_true, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot()
    plt.title('Matriz de Confusão')
    plt.show()

# Exemplo de uso
y_true = valores_verdadeiros_de_interacao  # Rótulos verdadeiros
y_pred = valor_predito_interacao_caixa_do_segmento_pose  # Rótulos previstos

criar_matriz_confusao(y_true, y_pred)

len(valor_predito_interacao_caixa_do_segmento_pose)

print(classification_report(y_true, y_pred))

#Calcula a acurácia
accuracy_score(y_true, y_pred)

#Calcula a precisão em porcentagem
precision_score(y_true, y_pred)*100

#Calcula o recall em porcentagem
recall_score(y_true, y_pred)*100

#Calcula o F1 Score em porcentagem
f1_score(y_true, y_pred)*100

"""### Análise da heurística se possui ponto chave dentro da segmentação"""

import os
import pandas as pd

# Caminho das labels de pose
imagens_pose_labels = '/content/gdrive/MyDrive/MESTRADO/Disciplinas/Visão Computacional/Estimativa de pose com yolo 11/Testes com yolo11/runs/pose/extra_large/labels'
# Caminhos das labels de segmentação
imagens_segmentacao_labels = '/content/gdrive/MyDrive/MESTRADO/Disciplinas/Visão Computacional/Segmentação com SAM2/predict/labels'

# Ordena os arquivos de pose e segmentação
caminhos_pose = sorted([os.path.join(imagens_pose_labels, label) for label in os.listdir(imagens_pose_labels)])
caminhos_segmentacao = sorted([os.path.join(imagens_segmentacao_labels, label) for label in os.listdir(imagens_segmentacao_labels)])

# Define as colunas da tabela de pose
colunas_pose = ["classe", "x_caixa", "y_caixa", "w_caixa", "h_caixa", "x_nariz", "y_nariz", "nariz-visibility", "x_olho_esq", "y_olho_esq", "olho_esq-visibility",
                "x_olho_dir", "y_olho_dir", "olho_dir-visibility", "x_orelha_esq", "y_orelha_esq", "orelha_esq-visibility",
                "x_orelha_dir", "y_orelha_dir", "orelha_dir-visibility", "x_ombro_esq", "y_ombro_esq", "ombro_esq-visibility",
                "x_ombro_dir", "y_ombro_dir", "ombro_dir-visibility", "x_cotovelo_esq", "y_cotovelo_esq", "cotovelo_esq-visibility",
                "x_cotevelo_dir", "y_cotevelo_dir", "cotevelo_dir-visibility", "x_pulso_esq", "y_pulso_esq", "pulso_esq-visibility",
                "x_pulso_dir", "y_pulso_dir", "pulso_dir-visibility", "x_quadril_esq", "y_quadril_esq", "quadril_esq-visibility",
                "x_quadril_dir", "y_quadril_dir", "quadril_dir-visibility", "x_joelho_esq", "y_joelho_esq", "joelho_esq-visibility",
                "x_joelho_dir", "y_joelho_dir", "joelho_dir-visibility", "x_tornozelo_esq", "y_tornozelo_esq", "tornozelo_esq-visibility",
                "x_tornozelo_dir", "y_tornozelo_dir", "tornozelo_dir-visibility", "conf"]

# Array para armazenar as predições de interação entre segmentação e pose
valor_predito_interacao_segmento_pose = []

largura = 1920  # Largura da imagem
altura = 1080  # Altura da imagem

# Função para verificar se o ponto está dentro do polígono da segmentação
def ponto_dentro_segmento(pulso, coordenadas_segmento):
    x, y = pulso
    # Verifica se o ponto (x, y) está dentro do polígono formado pelas coordenadas da segmentação
    n = len(coordenadas_segmento)
    dentro = False
    for i in range(n):
      if (x):
        j = (i + 1) % n
        xi, yi = coordenadas_segmento[i]
        xj, yj = coordenadas_segmento[j]
        if ((yi > y) != (yj > y)) and (x < (xj - xi) * (y - yi) / (yj - yi) + xi):
            dentro = not dentro
    return dentro

# Processamento de cada arquivo de pose e segmentação
for caminho_label in caminhos_pose:
    nome_arquivo = os.path.basename(caminho_label)

    df_pose = pd.read_csv(caminho_label, delimiter=' ', header=None, names=colunas_pose)

    caminho_label_segmento = os.path.join(imagens_segmentacao_labels, nome_arquivo)
    df_segmento = pd.read_csv(caminho_label_segmento, delimiter=' ', header=None)

    # Processar as coordenadas de segmentação
    # Remover a coluna de classe (primeira) e a coluna de confiabilidade (última)
    coordenadas_segmento = df_segmento.iloc[:, 1:-1].values #Pega somente as colunas com coordenadas
    segmento_coordenadas = []
    #Itera de 2 em 2, percorrendo os valores das coordenadas x
    for row in coordenadas_segmento:
        for i in range(0, len(row), 2):
            #Armazena o x e y dernormalizados de cada coordenada
            segmento_coordenadas.append([row[i] * largura, row[i + 1] * altura])

    # Array para armazenar se o pulso está dentro da segmentação
    interacao_pulsos = 0

    # Processar as estimativas de pose (pulso esquerdo e direito)
    for i in range(len(df_pose)):
        dados = df_pose.iloc[i]

        # Desnormalizar os pulsos (esquerdo e direito)
        x_pulso_esquerdo = dados.iloc[32] * largura
        y_pulso_esquerdo = dados.iloc[33] * altura
        x_pulso_direito = dados.iloc[35] * largura
        y_pulso_direito = dados.iloc[36] * altura

        # Verificar se os pulsos estão dentro da segmentação
        if ponto_dentro_segmento((x_pulso_esquerdo, y_pulso_esquerdo), segmento_coordenadas) or ponto_dentro_segmento((x_pulso_direito, y_pulso_direito), segmento_coordenadas):
            interacao_pulsos = 1  # Pelo menos um pulso está dentro da segmentação
            break  # Não precisamos verificar mais pessoas, podemos sair do loop

    # Adicionar o resultado da interação para o arquivo atual
    valor_predito_interacao_segmento_pose.append(interacao_pulsos)

# Exibir os resultados finais
print("Resultados de interação (1 = pulso dentro do segmento, 0 = pulso fora):")
print(valor_predito_interacao_segmento_pose)

len(valor_predito_interacao_segmento_pose)

import pandas as pd
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, classification_report
import matplotlib.pyplot as plt

def criar_matriz_confusao(y_true, y_pred):
    """
    Cria uma matriz de confusão e a plota.

    Args:
        y_true: O vetor de rótulos verdadeiros.
        y_pred: O vetor de rótulos previstos.
        classes: Uma lista com os nomes das classes.
    """

    cm = confusion_matrix(y_true, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot()
    plt.title('Matriz de Confusão')
    plt.show()

# Exemplo de uso
y_true = valores_verdadeiros_de_interacao  # Rótulos verdadeiros
y_pred = valor_predito_interacao_segmento_pose  # Rótulos previstos

criar_matriz_confusao(y_true, y_pred)

print(classification_report(y_true, y_pred))

#Calcula a acurácia
accuracy_score(y_true, y_pred)

#Calcula a precisão em porcentagem
precision_score(y_true, y_pred)*100

#Calcula o recall em porcentagem
recall_score(y_true, y_pred)*100

#Calcula o F1 Score em porcentagem
f1_score(y_true, y_pred)*100